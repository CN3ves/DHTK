#############
Documentation
#############

DHTK is organised in three main parts, each representing a function or concept of the DHTK structure:

.. rubric:: **Core Modules**

The core modules define DHTK configurations, logging, system checks and extension loading.
These modules control DHTK's "start-up" forming the framework that underlying DHTK modularisation.

.. rubric:: **Extension modules**

The extension modules the modules adding DHTK's for information querying and retrieval functionalities.
DHTK modularity has most impact as new, stand-alone modules, can be easily integrated to extend DHTK capabilities.
Each extension added to DHTK is associated to a specific resource, database or data types and adds specific
functionalities tailored to the user's needs, making DHTK a highly adaptable project, focused on addressing
the community needs.

The current DHTK version focuses on retrieving and processing metadata for textual resources such as
`Project Gutenberg <https://www.gutenberg.org/>`_ and `Auchinkleck manuscript <https://auchinleck.nls.uk/>`_,
because of its immediate relevance in the Humanities community and the
lack of automatic tools available in order to exploit these specific resources.

.. rubric:: **Processing modules**

**Linked Data**:
One of the most important aspects for a Humanities researcher is not just the availability
of original data (*e.g.* text, sound, image) but also the metadata associated with it.
Unfortunately, not all repositories are not completely annotated. For example,
`Project Gutenberg <https://www.gutenberg.org/>`_ does not store the original
publishing date of its books, which can represent a problem if a corpus needs be
delimited to a decade of published literature.
Resources like `DBpedia <https://wiki.dbpedia.org/>`_ , thanks to its
encyclopedic nature, helps to rethink these elements. DHTK data mining functionalities
make use of the principles of the
`Linked Open Data <https://en.wikipedia.org/wiki/Linked_data>`_  to explore
available Web resources and identify relevant metadata to simplify collection of the most
relevant metadata.

**Machine Learning**:
Recent years have seen major developments of computational methods of statistical,
classification and prediction analyses, These methods can automate many routine analyses,
with gains in speed and often accuracy, helping the researcher to further explore and
generate new insights from the relevant dataset. Unfortunately, many of these methods
require an understanding of advanced programming, algorithmic and mathematical concepts,
making it difficult to use by non-specialists. DHTK aims to progressively make these
`machine learning <https://en.wikipedia.org/wiki/Machine_learning>`_ methods
(*e.g* natural language processing, image processing) easily accessible to the Humanities scholar.

.. seealso:: `API reference <14_api.html>`_

.. toctree::
   :hidden:
   :maxdepth: 3

   Getting started <11_intro>
   User guide <12_guide>
   Developer guide <13_devs>
   API details <14_api>

